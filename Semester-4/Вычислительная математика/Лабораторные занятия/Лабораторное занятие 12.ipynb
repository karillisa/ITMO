{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab461380",
   "metadata": {},
   "source": [
    "# Практическая работа 12: Исследование работы LLM в контексте работы с собственными числами матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4218c1a",
   "metadata": {},
   "source": [
    "Ваше ФИО: \n",
    "\n",
    "Гафурова Фарангиз Фуркатовна (373432)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cde448",
   "metadata": {},
   "source": [
    "Что хотим сегодня изучить:\n",
    "1. Реализации методов поиска собственных значений и собственных векторов на Python\n",
    "2. Метод главных компонент, который много где используется сам по себе и основан на работе с собственными значениями матриц\n",
    "3. Метод главных компонент для оптимизации (уменьшения размеров) модели LLM\n",
    "4. Общение с AI-ассистентами (готовыми LLM) для исследования (изучения) новой предметной области (пункт 3 из списка ниже)\n",
    "5. Научиться писать промпты к LLM так, чтобы получать адекватные и неадекватные результаты (галлюцинации)\n",
    "6. Находить и устранять галлюцинации LLM в программировании и исследовании, когда предметная область Вам уже знакома (пункт 2 из списка ниже)\n",
    "7. Научиться оптимизировать модели LLM и проверять их точность (пункт 1 из списка ниже)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f4964",
   "metadata": {},
   "source": [
    "В контексте использования large language model (LLM) термин \"исследование\" обычно относится к процессу изучения, разработки или применения LLM для достижения научных, технических или академических целей. Он может иметь несколько значений в зависимости от конкретного контекста:\n",
    "\n",
    "1. **Разработка модели**: Исследование включает в себя создание или совершенствование LLM, включая проектирование архитектуры, оптимизацию алгоритмов обучения или повышение производительности (например, точности, результативности или обобщения). Этим часто занимаются исследователи ИИ или инженеры.\n",
    "\n",
    "2. **Изучение возможностей**: Исследование может означать изучение того, что могут делать LLM, например, тестирование их способности решать конкретные задачи (например, понимать естественный язык, рассуждать или генерировать код) или оценку их ограничений и предубеждений.\n",
    "\n",
    "3. **Применение к предметной области**: Использование LLMS для поддержки исследований в других областях, таких как анализ научной литературы, генерация гипотез или автоматизация обработки данных в таких дисциплинах, как медицина, физика или социальные науки.\n",
    "\n",
    "4. **Влияние на этику и общество**: Изучение последствий внедрения LLM, включая справедливость, безопасность, риски дезинформации или экологические издержки, связанные с обучением и выводами.\n",
    "\n",
    "Например, исследователь может использовать LLM для анализа обширных наборов данных для исследования (прикладной работы) или для экспериментов с тонкой настройкой, чтобы улучшить производительность при выполнении узкоспециализированной задачи (разработка). Термин является широким, но обычно подразумевает систематическое изучение или экспериментирование с участием LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbe6b7",
   "metadata": {},
   "source": [
    "### **План работы (разделы ноутбука)**\n",
    "1. Выбрать один или несколько AI-ассистентов из списка ниже и перечислить их ниже.\n",
    "2. Написать промпт (желательно один, чтобы можно было корректнее сравнить результат) на любой языке, на котором Вы ожидаете получить лучший результат, в результате которого выбрать модель с весами LLM для скачивания. Далее будем работать с этой моделью как с матрицей. Сравните ответы полученные от разных LLM в таблице. \n",
    "3. После этого с помощью того же или нового набора AI-ассистентов, получите сниппет для скачивания и начала работы с моделью. Вставьте сниппеты в соответствующие ячейки. Запустите ячейки и сравните полученные результаты, не внося дополнительных изменений в код, если он не работает.\n",
    "4. Если код после запуска не работает, получите у соответствующего AI-ассистента рекомендации по исправлению кода. Вставьте исправленный код в новую соответствующую ячейку. Запустите код и в случае, если код снова не работает, получите новые исправления. Продолжайте либо, пока код не заработает, либо пока AI-ассистент не начнёт слишком сильно галлюцинировать. Протоколируйте все диалоги в соответствующие ячейки. Проведите анализ полученных результатов в текущем разделе.\n",
    "5. Напишите собственные реализации методов нахождения собственных чисел и собственных векторов матриц, используя вызовы готовых реализаций в стандартных библиотеках или подробные описания.\n",
    "6. Заставьте AI-агентов написать сниппеты для тех же методов. Сравните на любой матрце.\n",
    "7. Исследуйте метод главных компонент для оптимизации размера выбранной модели при помощи собственных значений и собственных векторов. Сравните результаты работы модели до и после оптимизации.\n",
    "8. Заключение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d76d05",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db8ee5",
   "metadata": {},
   "source": [
    "## Раздел 1. Выбрать один или несколько AI-ассистентов из списка ниже и перечислить их ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204eb72",
   "metadata": {},
   "source": [
    "Список:\n",
    "\n",
    "- [ChatGPT (OpenAI)](https://chatgpt.com/)\n",
    "- [Claude (Anthropic)](https://claude.online/chat)\n",
    "- [Gemini (Google)](https://gemini.google.com/app)\n",
    "- [Grok (xAI)](https://grok.com/)\n",
    "- [Perplexity](https://www.perplexity.ai/)\n",
    "- [DeepSeek](https://chat.deepseek.com/)\n",
    "- [Qwen](https://chat.qwen.ai/)\n",
    "- [Llama (Meta AI)](https://huggingface.co/chat/) c учетной записью от Hugging Face\n",
    "- [Mistral](https://mistral.ai/)\n",
    "- [OpenAssistant](https://open-assistant.io/chat/)\n",
    "- [GigaChat (Sber)](https://giga.chat/#chat)\n",
    "\n",
    "- [Microsoft Copilot](https://copilot.microsoft.com/chats/)\n",
    "- [Tabnine](https://www.tabnine.com/pricing/) - платно, но есть триал\n",
    "- [Amazon Q Developer](https://aws.amazon.com/ru/q/developer/)\n",
    "- [GitHub Copilot](https://github.com/copilot)\n",
    "\n",
    "Вы также можете использовать модели, которые не попали в список, но обязательно указывайте их источник, название и прочие аттрибуты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62beac30",
   "metadata": {},
   "source": [
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "[Qwen](https://chat.qwen.ai/)\n",
    "\n",
    "[Claude (Anthropic)](https://claude.online/chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6e50e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b97a90",
   "metadata": {},
   "source": [
    "## Раздел 2. Написать промпт, отправить AI-ассистентам, сравнить результаты\n",
    "2.1. Написать промпт (желательно один, чтобы можно было корректнее сравнить результат) на любой языке, на котором Вы ожидаете получить лучший результат, в результате которого **выбрать** модель с весами LLM для скачивания (желательно выбирать небольшие модели, чтобы скачивать было не много и матрицы были не слишком большими). Далее будем работать с этой моделью как с матрицей.\n",
    "\n",
    "2.2. Отправить промпт AI-ассистентам, выбранным в разделе 1.\n",
    "\n",
    "2.3. Сравните ответы полученные от разных LLM в таблице.\n",
    "\n",
    "2.4. Выбрать модель для скачивания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a51121",
   "metadata": {},
   "source": [
    "### 2.1 Использованный промпт:\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "Пожалуйста, предложи мне несколько небольших моделей с весами LLM (Large Language Model), которые можно скачать для дальнейшей работы с ними как с матрицей. Модели должны быть небольшими по размеру для экономии времени скачивания и чтобы матрицы, с которыми они будут работать, не были слишком большими. В ответе укажи название модели, ее размер и ссылку на источник скачивания, если таковая есть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e8ddc",
   "metadata": {},
   "source": [
    "### 2.3. Сравнение результатов\n",
    "\n",
    "| **Ассистент** | **Ответ** |**Ваш комментарий**|\n",
    "|---|---|---|\n",
    "|Qwen|Смотреть ниже☺|Qwen предложила достаточно широкий спектр небольших по размеру языковых моделей с открытыми весами, которые могут быть полезны для дальнейших исследований и экспериментов с матрицами.|\n",
    "|Claude (Anthropic)|Тоже смотреть ниже☺|В отличии от Qwen Claude (Anthropic) не стал подробно расписывать модели, а просто вывел общую информацию по заданным требованиям.|\n",
    "\n",
    "**Ассистент** : Qwen\n",
    "\n",
    "**Ответ**:\n",
    "\n",
    "Вот несколько **небольших по размеру** и **легко используемых** языковых моделей с открытыми весами, которые ты можешь скачать и использовать в виде матриц (например, для исследования, экспериментов или обучения):\n",
    "\n",
    "1. **TinyLlama**\n",
    "- **Описание**: Обучена на ~3 триллиона токенов, содержит всего **110 миллионов параметров**, но при этом показывает довольно хорошую производительность для своей компактности.\n",
    "- **Размер модели (~110M)**: около **200–300 МБ** (в зависимости от формата хранения)\n",
    "- **Ссылка для скачивания**:  \n",
    "  [TinyLlama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n",
    " 2. **StableBeluga Base (70M)**\n",
    "- **Описание**: Очень маленькая версия от компании StabilityAI / Together Research.\n",
    "- **Размер модели (~70M)**: около **150 МБ**\n",
    "- **Ссылка**: [HuggingFace - stabilityai/stable-beluga-base](https://huggingface.co/stabilityai/stable-beluga-base)\n",
    "\n",
    " 3. **DistilGPT2**\n",
    "- **Описание**: Упрощённая и ускоренная версия GPT-2 (в 2 раза меньше), оптимизированная за счет дистилляции знаний.\n",
    "- **Размер модели (~80M)**: около **150 МБ**\n",
    "- **Ссылка**: [HuggingFace - distilgpt2](https://huggingface.co/distilgpt2)\n",
    "\n",
    "4. **Pythia-70M / Pythia-160M**\n",
    "- **Описание**: Серия небольших моделей проекта EleutherAI, обученных на большом объеме данных.\n",
    "- **Размеры**:\n",
    "  - `pythia-70m`: ~130 МБ\n",
    "  - `pythia-160m`: ~290 МБ\n",
    "- **Ссылки**:\n",
    "  - [HuggingFace - pythia-70m](https://huggingface.co/EleutherAI/pythia-70m)\n",
    "  - [HuggingFace - pythia-160m](https://huggingface.co/EleutherAI/pythia-160m)\n",
    "\n",
    " 5. **Llama.cpp (мини-модели, квантованные)**\n",
    "Если тебе подойдут **квантованные модели**, то можно использовать например `ggml-model-gpt-2-355M.bin` или другие в формате `.bin`. Они легче обрабатываются и занимают меньше памяти.\n",
    "\n",
    "- **Модель**: `gpt-2-355M` – ~355 млн параметров, можно найти квантованную до ~200–300 МБ\n",
    "- **Ссылка**: \n",
    "  [llama.cpp GGML models](https://github.com/ggerganov/llama.cpp#readme)\n",
    "\n",
    " Рекомендации по работе:\n",
    "\n",
    "- Используй библиотеки `transformers`, `torch` или `onnxruntime` для загрузки и извлечения весов как матриц.\n",
    "- Веса можно получить напрямую через атрибуты `model.state_dict()` в PyTorch.\n",
    "- Для работы с меньшими вычислениями используй **float16** или **int8** версии моделей.\n",
    "\n",
    "\n",
    "**Ассистент** : Claude (Anthropic)\n",
    "\n",
    "**Ответ** : \n",
    "Конечно! Вот несколько небольших моделей LLM, которые можно скачать и использовать:\n",
    "\n",
    "1. DistilBERT\n",
    "\n",
    "Размер: ~66 МБ\n",
    "\n",
    "Источник: Hugging Face Model Hub\n",
    "\n",
    "2. TinyBERT\n",
    "\n",
    "Размер: ~14 МБ\n",
    "\n",
    "Источник: Hugging Face Model Hub\n",
    "\n",
    "3. ALBERT (Base)\n",
    "\n",
    "Размер: ~12 МБ\n",
    "\n",
    "Источник: Hugging Face Model Hub\n",
    "\n",
    "4. MobileBERT\n",
    "\n",
    "Размер: ~25 МБ\n",
    "\n",
    "Источник: Hugging Face Model Hub\n",
    "\n",
    "5. MiniLM\n",
    "\n",
    "Размер: ~22 МБ\n",
    "\n",
    "Источник: Hugging Face Model Hub\n",
    "\n",
    "Эти модели являются легковесными и подходят для различных задач обработки естественного языка. Вы можете использовать Hugging Face для их загрузки и работы с ними как с матрицами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbdf48",
   "metadata": {},
   "source": [
    "### 2.4. Выбранная модель\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "TinyLIama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec640cab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe2f28",
   "metadata": {},
   "source": [
    "## Раздел 3. Скачивание модели с помощью сниппетов от AI-ассистентов\n",
    "С помощью того же или нового набора AI-ассистентов, получите сниппет для скачивания и начала работы с моделью. Вставьте сниппеты в соответствующие ячейки. Запустите ячейки и сравните полученные результаты, не внося дополнительных изменений в код, если он не работает.\n",
    "\n",
    "3.1. Список используемых AI\n",
    "\n",
    "\n",
    "3.2. Сниппеты для скачивания выбранной модели\n",
    "\n",
    "3.3. Запуск сниппетов\n",
    "\n",
    "3.4. Анализ результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5060669",
   "metadata": {},
   "source": [
    "### 3.1. Список используемых AI\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "Qwen (https://chat.qwen.ai/)\n",
    "\n",
    "Claude (Anthropic) (https://claude.online/chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9967ae",
   "metadata": {},
   "source": [
    "### 3.2. Сниппеты для скачивания выбранной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca6dc9d",
   "metadata": {},
   "source": [
    "Модель 1: Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61a4cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Скачивание модели...\n",
      "❌ Ошибка при загрузке модели: roneneldan/TinyLlama-1.1B is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
      "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
      "\n",
      "🔍 Веса слоёв модели:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 4️⃣ Извлечение весов как матриц\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔍 Веса слоёв модели:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m.named_parameters():\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Получаем веса эмбеддингов\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 1️⃣ Проверка установки библиотек (раскомментируй, если нужно)\n",
    "os.system(\"pip install transformers torch\")\n",
    "\n",
    "# 2️⃣ Настройки модели\n",
    "model_name = \"roneneldan/TinyLlama-1.1B\"\n",
    "model_save_path = \"./tinyllama_model\"\n",
    "weights_file = \"./tinyllama_weights.pt\"\n",
    "embedding_weights_file = \"./tinyllama_embeddings.pt\"\n",
    "\n",
    "# 3️⃣ Скачивание и сохранение модели локально\n",
    "print(\"📥 Скачивание модели...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    # Сохранить модель локально (для офлайн использования)\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    print(f\"💾 Модель сохранена в папку: {model_save_path}\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Ошибка при загрузке модели:\", str(e))\n",
    "    exit()\n",
    "\n",
    "# 4️⃣ Извлечение весов как матриц\n",
    "print(\"\\n🔍 Веса слоёв модели:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} -> {param.shape}\")\n",
    "\n",
    "# Получаем веса эмбеддингов\n",
    "try:\n",
    "    embedding_weights = model.get_input_embeddings().weight\n",
    "    print(\"\\n🔤 Форма весов эмбеддингов:\", embedding_weights.shape)\n",
    "\n",
    "    # Пример: получить веса одного из слоёв\n",
    "    first_layer_weights = model.model.layers[0].mlp.down_proj.weight\n",
    "    print(\"🔢 Форма весов первого MLP слоя:\", first_layer_weights.shape)\n",
    "except Exception as e:\n",
    "    print(\"❌ Ошибка при извлечении весов:\", str(e))\n",
    "\n",
    "# 5️⃣ Сохраняем веса в файлы\n",
    "try:\n",
    "    print(\"\\n📦 Сохранение весов в файлы...\")\n",
    "    torch.save(model.state_dict(), weights_file)\n",
    "    torch.save(embedding_weights, embedding_weights_file)\n",
    "    print(f\"✅ Все веса сохранены в файл: {weights_file}\")\n",
    "    print(f\"✅ Веса эмбеддингов сохранены в файл: {embedding_weights_file}\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Ошибка при сохранении весов:\", str(e))\n",
    "\n",
    "# 6️⃣ Загрузка весов обратно (пример)\n",
    "try:\n",
    "    loaded_weights = torch.load(weights_file)\n",
    "    print(\"\\n📂 Загружены веса из файла:\", loaded_weights.keys())\n",
    "except Exception as e:\n",
    "    print(\"❌ Ошибка при загрузке весов из файла:\", str(e))\n",
    "\n",
    "# 7️⃣ Пример генерации текста\n",
    "try:\n",
    "    prompt = \"Hello, I am TinyLlama and I can say that\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"\\n✍️ Сгенерированный текст:\\n\", generated_text)\n",
    "except Exception as e:\n",
    "    print(\"❌ Ошибка при генерации текста:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dea61d",
   "metadata": {},
   "source": [
    "Модель 2: Claude (Anthropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a84259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gafur\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gafur\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gafur\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c878d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "huggyllama/tinylama is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/huggyllama/tinylama/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:961\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1068\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1596\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1593\u001b[39m ):\n\u001b[32m   1594\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1595\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1401\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:285\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m response = get_session().request(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 401 Client Error. (Request ID: Root=1-681102dd-30efe4ed0123355e754eb104;c38395b2-75e1-4674-af70-d11356eaca9e)\n\nRepository Not Found for url: https://huggingface.co/huggyllama/tinylama/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mОтвет:\u001b[39m\u001b[33m\"\u001b[39m, response)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mhuggyllama/tinylama\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Скачивание токенизатора и модели\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m model = AutoModelForCausalLM.from_pretrained(model_name)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Пример использования\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:946\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m    948\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:778\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    775\u001b[39m     token = use_auth_token\n\u001b[32m    777\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    795\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    209\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    210\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    211\u001b[39m     **kwargs,\n\u001b[32m    212\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:456\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    457\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    464\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: huggyllama/tinylama is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def main():\n",
    "    # Задайте имя модели\n",
    "    model_name = \"huggyllama/tinylama\"\n",
    "\n",
    "    # Скачивание токенизатора и модели\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    # Пример использования\n",
    "    input_text = \"Hello, how can I use TinyLlama?\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Генерация ответа\n",
    "    outputs = model.generate(**inputs)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Ответ:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d188a",
   "metadata": {},
   "source": [
    "Модель 3: Название вашего ассистента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dabfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201abe2b",
   "metadata": {},
   "source": [
    "### 3.4. Анализ результатов\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "Оба ассистента выдали сниппеты для скачивания модели TinyLIama, но тем не менее при запуске оба кода выдали ошибку. Будем разбираться дальше =)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d4af1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a780f7",
   "metadata": {},
   "source": [
    "## Раздел 4. Первые галлюцинации\n",
    "Если код после запуска не работает, получите у соответствующего AI-ассистента рекомендации по исправлению кода. Вставьте исправленный код в новую соответствующую ячейку. Запустите код и в случае, если код снова не работает, получите новые исправления. Продолжайте либо, пока код не заработает, либо пока AI-ассистент не начнёт слишком сильно галлюцинировать. Протоколируйте все диалоги в соответствующие ячейки. Проведите анализ полученных результатов в текущем разделе.\n",
    "\n",
    "В случае, если все модели отработали безупречно, вернитесь к этому разделу после промта по написанию методов рассчёта собственных значений матрицы (раздел 6) или оптимизации выбранной модели LLM при помощи методов поиска собственных значений и собственных векторов матрицы весов. (раздел 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63171b0e",
   "metadata": {},
   "source": [
    "#### Справка: Когда LLM начинают галлюцинировать?\n",
    "\n",
    "**LLMs склонны к галлюцинациям во время написания кода, главным образом, в таких ситуациях:**\n",
    "\n",
    "1. **Неоднозначные или недостаточно определенные запросы**  \n",
    "   - Если запрос расплывчатый (\"напишите алгоритм быстрой сортировки\"), то LLM может начать гадать и выдумывать детали.\n",
    "2. **Редкие или незнакомые библиотеки, API или фреймворки**  \n",
    "   - Если Вы спрашиваете о малоизвестном инструменте или совершенно новой версии библиотеки, LLM может \"придумать\" методы, классы или шаблоны использования на основе шаблонов, которые он видел в других местах.\n",
    "3. **Междоменные запросы**  \n",
    "   - При объединении технологий (например, \"использовать модели SQLAlchemy внутри конвейера TensorFlow\") могут возникнуть галлюцинации с API, которых на самом деле не существует.\n",
    "4. **Устаревшие или будущие знания**  \n",
    "   - Если что-то изменилось после завершения обучения модели (например, новые возможности версии Python), она может придумать поведение, которое \"ожидает\", основываясь на тенденциях.\n",
    "5. **Сложные многоэтапные задачи**  \n",
    "   - В более длинных цепочках (например, при полной настройке приложения) накапливаются ошибки - пропущенный импорт, неправильные типы, воображаемые функции и т.д.\n",
    "6. **Когда вас просят оптимизировать, упростить или сильно обобщить**  \n",
    "   - \"Напишите наиболее эффективную систему кэширования\" — это может привести к созданию идеализированных методов, которые звучат правдоподобно, но не являются реальными.\n",
    "7. **Слишком самоуверенные формулировки в запросах**  \n",
    "   - Если вы спросите \"Дайте мне точный вызов API для...\" с полной уверенностью, модель может выдать очень уверенный, но совершенно неверный ответ.\n",
    "\n",
    "**Как распознать галлюцинации, когда LLMs пишут код:**\n",
    "\n",
    "- **Сверьтесь с официальной документацией.**  \n",
    "  Всегда сверяйте названия функций, сигнатуры методов и использование библиотек с реальной документацией.\n",
    "\n",
    "- **Запустите и протестируйте код на ранней стадии.**  \n",
    "  Даже небольшой пример (модульный тест, выполнение скрипта) может сразу выявить недостоверные детали.\n",
    "\n",
    "- **Используйте средства проверки типов и линтеры.**  \n",
    "  Такие инструменты, как \"mypy\", \"pylint\" или \"eslint\", часто обнаруживают (*выдуманные*) ошибочные API, неправильный импорт и т.д.\n",
    "\n",
    "- **Задавайте дополнительные вопросы.**  \n",
    "  Если вы не уверены, вы можете спросить у LLM: \"Вы уверены, что `foo.bar()` существует? Можете ли вы показать документацию?\". Но в последних версиях LLM поголовно научились нагло врать, наставать и выдумывать ссылки.\n",
    "\n",
    "- **Будьте подозрительны к слишком точным ответам.**  \n",
    "  Реальный код часто требует обработки ошибок, нестандартных ситуаций, шагов по настройке. Галлюцинированный код часто выглядит \"слишком чистым\".\n",
    "\n",
    "- **Делайте подсказки конкретными.**  \n",
    "  Сужение задачи снижает вероятность того, что модель ошибется в своих предположениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8c772",
   "metadata": {},
   "source": [
    "Модель 1: Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7dba27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Загрузка модели 'gpt2'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔤 Токенизация...\n",
      "✍️ Генерация текста...\n",
      "\n",
      "📄 Сгенерированный текст:\n",
      "Artificial Intelligence is a new way of thinking about the world, and it's not just a scientific term. It's a very important concept in science, the field of artificial intelligence, where it is able to take on the role of an artificial general intelligence and transform it into something real.\n",
      "\n",
      "JAMIE QUERIE: I want to talk to you about this, I really want you to be very interested in this. I'm Amy Querie, this is Democracy Now! I am a reporter for\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def generate_response(model_name=\"gpt2\", input_text=\"Hello, how are you?\"):\n",
    "    try:\n",
    "        # Загрузка токенизатора и модели\n",
    "        print(f\"📥 Загрузка модели '{model_name}'...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "        # Токенизация входного текста\n",
    "        print(\"🔤 Токенизация...\")\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "        # Генерация ответа с настройками\n",
    "        print(\"✍️ Генерация текста...\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=100,     # Максимум новых токенов\n",
    "            num_return_sequences=1, # Количество возвращаемых последовательностей\n",
    "            no_repeat_ngram_size=2, # Избегание повторений\n",
    "            do_sample=True,         # Включить случайность\n",
    "            top_k=50,               # Top-k sampling\n",
    "            top_p=0.95,             # Nucleus sampling\n",
    "            temperature=0.7         # Температура для контроля случайности\n",
    "        )\n",
    "\n",
    "        # Декодирование результата\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(\"\\n📄 Сгенерированный текст:\")\n",
    "        print(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Можно попробовать другие модели, например:\n",
    "    # \"distilgpt2\", \"EleutherAI/gpt-neo-125M\", \"PY007/TinyLlama-1.1B-python\"\n",
    "    generate_response(model_name=\"gpt2\", input_text=\"Artificial Intelligence is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df429626",
   "metadata": {},
   "source": [
    "Модель 2: Claude (Anthropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1223908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ: Hello, how can I use GPT-2?\n",
      "\n",
      "GPT-2 is a new version of the standard library. It is a new version\n"
     ]
    }
   ],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def main():\n",
    "    # Задайте имя модели\n",
    "    model_name = \"gpt2\"  # Замените на корректное имя модели\n",
    "\n",
    "    # Скачивание токенизатора и модели\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    # Пример использования\n",
    "    input_text = \"Hello, how can I use GPT-2?\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Генерация ответа\n",
    "    outputs = model.generate(**inputs)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Ответ:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e8d29",
   "metadata": {},
   "source": [
    "Модель 3: Название вашего ассистента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31523c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b7f6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a135f37",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdaff9f",
   "metadata": {},
   "source": [
    "## Раздел 5. Набросаем код методов самостоятельно из готовой документации\n",
    "\n",
    "Реализуйте расчёт собственных значений матриц весов любого слоя при помощи известных Вам методов самостоятельно, используя стандартные библиотеки Python.\n",
    "\n",
    "Выполните это задание самостоятельно, а не при помощи ассистентов (**любых**, включая GitHub Copilot autocomplite, его можно отключить в настройках справа внизу, Google Colab Gemini тоже можнот отключить в настройках \"Инструменты\"-\"ИИ-функции\"-\"Предлагать подсказки ИИ для дополнения кода\"), чтобы можно было корректно сравнить результаты стандартных библиотек и сниппетов, которые предложат Вам ассистенты далее.\n",
    "\n",
    "\n",
    "| Метод | Функция Python | Библиотека | Ссылка на документацию |\n",
    "|---|---|---|---|\n",
    "|Power Method (Dominant Eigenvalue) | Manual (template provided) | Custom/Numpy | [Tutorial](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Approximating_Eigenvalues.html#power-method) or [template](https://en.wikipedia.org/wiki/Power_iteration#Numerical_example) — implement with `numpy.dot` |\n",
    "|Shifted Power Method | Manual + `numpy.linalg.solve` | Numpy | [Tutorial](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Approximating_Eigenvalues.html) |\n",
    "|QR Algorithm (Full Spectrum) | `scipy.linalg.eig` or `numpy.linalg.eig` | Scipy/Numpy | [scipy.linalg.eig](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eig.html) / [numpy.linalg.eig](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html) |\n",
    "|Full QR Decomposition (optional deeper understanding) | `numpy.linalg.qr` | Numpy | [numpy.linalg.qr](https://numpy.org/doc/stable/reference/generated/numpy.linalg.qr.html) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773b4940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Method - Dominant Eigenvalue: 2.9999999123096748\n",
      "Power Method - Dominant Eigenvector: [0.70704633 0.70716722]\n",
      "Shifted Power Method - Eigenvalue: 1.0000000342456419\n",
      "Shifted Power Method - Eigenvector: [-0.70704135  0.70717221]\n",
      "QR Algorithm - Eigenvalues: [3.+0.j 1.+0.j]\n",
      "QR Algorithm - Eigenvectors: [[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "\n",
    "def power_method(A, num_iterations=100, tolerance=1e-6):\n",
    "    n = A.shape[0]\n",
    "    x = np.random.rand(n)\n",
    "    x = x / np.linalg.norm(x)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        y = np.dot(A, x)\n",
    "        lambda_new = np.linalg.norm(y)\n",
    "        x = y / lambda_new\n",
    "\n",
    "        if _ > 0:\n",
    "            if np.abs(lambda_new - lambda_old) < tolerance:\n",
    "                break\n",
    "        lambda_old = lambda_new\n",
    "\n",
    "    return lambda_new, x\n",
    "\n",
    "\n",
    "def shifted_power_method(A, shift, num_iterations=100, tolerance=1e-6):\n",
    "    n = A.shape[0]\n",
    "    x = np.random.rand(n)\n",
    "    x = x / np.linalg.norm(x)\n",
    "\n",
    "    B = A - shift * np.eye(n)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        y = np.linalg.solve(B, x)\n",
    "        lambda_new = np.linalg.norm(y)\n",
    "        x = y / lambda_new\n",
    "\n",
    "        if _ > 0:\n",
    "            if np.abs(lambda_new - lambda_old) < tolerance:\n",
    "                break\n",
    "        lambda_old = lambda_new\n",
    "\n",
    "    return shift + 1 / lambda_new, x\n",
    "\n",
    "\n",
    "def qr_algorithm(A):\n",
    "    eigenvalues, eigenvectors = linalg.eig(A)\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "A = np.array([[2, 1],\n",
    "              [1, 2]])\n",
    "\n",
    "lambda_power, x_power = power_method(A)\n",
    "print(\"Power Method - Dominant Eigenvalue:\", lambda_power)\n",
    "print(\"Power Method - Dominant Eigenvector:\", x_power)\n",
    "\n",
    "shift = 0\n",
    "lambda_shifted, x_shifted = shifted_power_method(A, shift)\n",
    "print(\"Shifted Power Method - Eigenvalue:\", lambda_shifted)\n",
    "print(\"Shifted Power Method - Eigenvector:\", x_shifted)\n",
    "\n",
    "eigenvalues_qr, eigenvectors_qr = qr_algorithm(A)\n",
    "print(\"QR Algorithm - Eigenvalues:\", eigenvalues_qr)\n",
    "print(\"QR Algorithm - Eigenvectors:\", eigenvectors_qr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17fb7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ec577",
   "metadata": {},
   "source": [
    "## Раздел 6. AI-ассистенты пишут код для расчёта собственных значений и векторов матриц\n",
    "6.1. Напишите промпт для получения сниппетов методов расчёта собственных значений и векторов матриц.\n",
    "\n",
    "6.2. Сниппеты для расчёта собственных значений и векторов матриц\n",
    "\n",
    "6.3. Запуск сниппетов против любой выбранной Вами матрицы\n",
    "\n",
    "6.4. Анализ результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178daa2",
   "metadata": {},
   "source": [
    "### 6.1 Ваш промпт\n",
    "\n",
    "*ВАШ ПРОМПТ ЗДЕСЬ*\n",
    "\n",
    "Пожалуйста, предоставьте мне Python - сниппеты для реализации следующих методов расчета собственных значений и собственных векторов матриц: Метод Степени (Power Method) для нахождения главного собственного значения и соответствующего собственного вектора, Сдвинутый Метод Степени (Shifted Power Method) для нахождения других собственных значений и векторов, а также QR - алгоритм для нахождения всего спектра собственных значений и векторов. В сниппетах используйте стандартные библиотеки Python, такие как Numpy и Scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dadb9ce",
   "metadata": {},
   "source": [
    "### 6.2. Сниппеты для расчёта собственных значений и векторов матриц"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cf1f0",
   "metadata": {},
   "source": [
    "Модель 1: Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12c1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная матрица A:\n",
      " [[2. 1.]\n",
      " [1. 2.]] \n",
      "\n",
      "🔹 Метод Степени\n",
      "Наибольшее собственное значение: 3.0\n",
      "Соответствующий собственный вектор: [0.70710677 0.70710679]\n",
      "\n",
      "🔸 Сдвинутый Метод Степени\n",
      "Второе собственное значение: 1.0\n",
      "Соответствующий собственный вектор: [-0.70710679  0.70710677]\n",
      "\n",
      "🔹🔸 QR-алгоритм: все собственные значения:\n",
      "1-е собственное значение: 2.999999999999999\n",
      "Соответствующий собственный вектор: [0.70710678 0.70710678]\n",
      "\n",
      "2-е собственное значение: 0.9999999999999998\n",
      "Соответствующий собственный вектор: [-0.70710678  0.70710678]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей\n",
    "import numpy as np\n",
    "from scipy.linalg import qr, norm\n",
    "\n",
    "# ======================================================\n",
    "# 1. Метод Степени (Power Method)\n",
    "# ======================================================\n",
    "def power_method(A, num_iter=1000, tol=1e-8):\n",
    "    n = A.shape[0]\n",
    "    v = np.random.rand(n)\n",
    "    v /= norm(v)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        Av = A @ v\n",
    "        λ = np.dot(v, Av)\n",
    "        v_new = Av / norm(Av)\n",
    "\n",
    "        if norm(v_new - v) < tol:\n",
    "            break\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    return λ, v\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. Сдвинутый Метод Степени (Shifted Power Method)\n",
    "# ======================================================\n",
    "def shifted_power_method(A, μ, v1, num_iter=1000, tol=1e-8):\n",
    "    n = A.shape[0]\n",
    "    I = np.eye(n)\n",
    "    B = A - μ * I  # Сдвинутая матрица\n",
    "\n",
    "    v = np.random.rand(n)\n",
    "    v = v - np.dot(v, v1) * v1  # Ортогонализация к первому вектору\n",
    "    v /= norm(v)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        Bv = B @ v\n",
    "        λ_shifted = np.dot(v, Bv)\n",
    "        v_new = Bv / norm(Bv)\n",
    "        v_new = v_new - np.dot(v_new, v1) * v1  # Повторная ортогонализация\n",
    "        v_new /= norm(v_new)\n",
    "\n",
    "        if norm(v_new - v) < tol:\n",
    "            break\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    λ = λ_shifted + μ  # Возвращаем сдвиг\n",
    "    return λ, v\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. QR-алгоритм\n",
    "# ======================================================\n",
    "def qr_algorithm(A, num_iter=1000, tol=1e-8):\n",
    "    n = A.shape[0]\n",
    "    Ak = A.copy()\n",
    "    Qk = np.eye(n)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        Q, R = qr(Ak)\n",
    "        Ak = R @ Q\n",
    "        Qk = Qk @ Q\n",
    "\n",
    "        off_diag = Ak - np.diag(np.diagonal(Ak))\n",
    "        if norm(off_diag) < tol:\n",
    "            break\n",
    "\n",
    "    eigenvalues = np.diagonal(Ak)\n",
    "    eigenvectors = Qk\n",
    "\n",
    "    idx = np.argsort(-abs(eigenvalues))\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 🔍 Пример использования\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Пример матрицы\n",
    "    A = np.array([\n",
    "        [2, 1],\n",
    "        [1, 2]\n",
    "    ], dtype=float)\n",
    "\n",
    "    print(\"Исходная матрица A:\\n\", A, \"\\n\")\n",
    "\n",
    "    # 1. Power Method — главное собственное значение и вектор\n",
    "    λ1, v1 = power_method(A)\n",
    "    print(\"🔹 Метод Степени\")\n",
    "    print(\"Наибольшее собственное значение:\", λ1)\n",
    "    print(\"Соответствующий собственный вектор:\", v1)\n",
    "    print()\n",
    "\n",
    "    # 2. Shifted Power Method — второе собственное значение\n",
    "    λ2, v2 = shifted_power_method(A, μ=λ1, v1=v1)\n",
    "    print(\"🔸 Сдвинутый Метод Степени\")\n",
    "    print(\"Второе собственное значение:\", λ2)\n",
    "    print(\"Соответствующий собственный вектор:\", v2)\n",
    "    print()\n",
    "\n",
    "    # 3. QR Algorithm — полный спектр\n",
    "    eigenvalues, eigenvectors = qr_algorithm(A)\n",
    "    print(\"🔹🔸 QR-алгоритм: все собственные значения:\")\n",
    "    for i in range(len(eigenvalues)):\n",
    "        print(f\"{i+1}-е собственное значение: {eigenvalues[i]}\")\n",
    "        print(f\"Соответствующий собственный вектор: {eigenvectors[:, i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e330f",
   "metadata": {},
   "source": [
    "Модель 2: Claude (Anthropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189121a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод Степени:\n",
      "Главное собственное значение: 2.7048687322980847\n",
      "Соответствующий собственный вектор: [0.57204977 0.82021891]\n",
      "\n",
      "Сдвинутый Метод Степени:\n",
      "Собственное значение при сдвиге: 3.0381338394565542\n",
      "Соответствующий собственный вектор при сдвиге: [ 0.95127349 -0.30834842]\n",
      "\n",
      "QR-Алгоритм:\n",
      "Спектр собственных значений:\n",
      " [ 3. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей\n",
    "import numpy as np\n",
    "\n",
    "def power_method(A, num_iterations=100, tolerance=1e-6):\n",
    "    b_k = np.random.rand(A.shape[1])  # Начальный вектор\n",
    "    for _ in range(num_iterations):\n",
    "        # Находим следующий вектор\n",
    "        b_k1 = np.dot(A, b_k)\n",
    "        \n",
    "        # Нормируем вектор\n",
    "        b_k1_norm = np.linalg.norm(b_k1)\n",
    "        b_k = b_k1 / b_k1_norm\n",
    "        \n",
    "        # Проверка сходимости\n",
    "        if np.linalg.norm(b_k1 - b_k1_norm * b_k) < tolerance:\n",
    "            break\n",
    "    \n",
    "    eigenvalue = b_k1_norm\n",
    "    eigenvector = b_k\n",
    "    return eigenvalue, eigenvector\n",
    "\n",
    "def shifted_power_method(A, shift, num_iterations=100, tolerance=1e-6):\n",
    "    n = A.shape[0]\n",
    "    A_shifted = A - shift * np.eye(n)\n",
    "    return power_method(A_shifted, num_iterations, tolerance)\n",
    "\n",
    "def qr_algorithm(A, num_iterations=100):\n",
    "    A_k = A.copy()\n",
    "    for _ in range(num_iterations):\n",
    "        Q, R = np.linalg.qr(A_k)\n",
    "        A_k = R @ Q  # Обновляем матрицу\n",
    "    return A_k\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    A = np.array([[1, 2], [2, 1]])\n",
    "    \n",
    "    # Метод Степени\n",
    "    eigenvalue, eigenvector = power_method(A)\n",
    "    print(\"Метод Степени:\")\n",
    "    print(\"Главное собственное значение:\", eigenvalue)\n",
    "    print(\"Соответствующий собственный вектор:\", eigenvector)\n",
    "\n",
    "    # Сдвинутый Метод Степени\n",
    "    shift = 2.0  # Выберите сдвиг\n",
    "    eigenvalue_shifted, eigenvector_shifted = shifted_power_method(A, shift)\n",
    "    print(\"\\nСдвинутый Метод Степени:\")\n",
    "    print(\"Собственное значение при сдвиге:\", eigenvalue_shifted + shift)\n",
    "    print(\"Соответствующий собственный вектор при сдвиге:\", eigenvector_shifted)\n",
    "\n",
    "    # QR-Алгоритм\n",
    "    A_eigenvalues = qr_algorithm(A)\n",
    "    print(\"\\nQR-Алгоритм:\")\n",
    "    print(\"Спектр собственных значений:\\n\", np.diag(A_eigenvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d519c8",
   "metadata": {},
   "source": [
    "Модель 3: Название вашего ассистента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полученный сниппет для скачивания модели и начала работы как с матрицей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f50616",
   "metadata": {},
   "source": [
    "### 6.3. Запуск сниппетов на любой выбранной матрице и численное сравнение с вашей реализацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38af45ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты от Qwen:\n",
      "Метод Степени (Qwen)\n",
      "Наибольшее собственное значение: 2.8933130628904\n",
      "Соответствующий собственный вектор: [0.4129172  0.91076857]\n",
      "\n",
      "Ошибка при выполнении сдвинутого метода Степени от Qwen: shifted_power_method() got an unexpected keyword argument 'μ'\n",
      " QR-алгоритм (Qwen): все собственные значения:\n",
      "1-е собственное значение: 5.0\n",
      "Ошибка при выполнении QR - алгоритма от Qwen: too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "\n",
      "Результаты от Claude:\n",
      "Метод Степени (Claude)\n",
      "Главное собственное значение: 1.1815808034028914\n",
      "Соответствующий собственный вектор: [0.74012652 0.67246765]\n",
      "\n",
      "Сдвинутый Метод Степени (Claude)\n",
      "Собственное значение при сдвиге: 3.8633411785777922\n",
      "Соответствующий собственный вектор при сдвиге: [0.70710678 0.70710678]\n",
      "\n",
      "QR-алгоритм (Claude):\n",
      "Спектр собственных значений:\n",
      " [5. 3.]\n"
     ]
    }
   ],
   "source": [
    "# ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "# Выбранная матрица\n",
    "A = np.array([[4, 1],\n",
    "              [1, 4]])\n",
    "\n",
    "# Использование сниппетов от Qwen\n",
    "print(\"Результаты от Qwen:\")\n",
    "try:\n",
    "    λ1_qwen, v1_qwen = power_method(A)\n",
    "    print(\"Метод Степени (Qwen)\")\n",
    "    print(\"Наибольшее собственное значение:\", λ1_qwen)\n",
    "    print(\"Соответствующий собственный вектор:\", v1_qwen)\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при выполнении метода Степени от Qwen: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    λ2_qwen, v2_qwen = shifted_power_method(A, μ=λ1_qwen, v1=v1_qwen)\n",
    "    print(\"Сдвинутый Метод Степени (Qwen)\")\n",
    "    print(\"Второе собственное значение:\", λ2_qwen)\n",
    "    print(\"Соответствующий собственный вектор:\", v2_qwen)\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при выполнении сдвинутого метода Степени от Qwen: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    eigenvalues_qr_qwen, eigenvectors_qr_qwen = qr_algorithm(A)\n",
    "    print(\" QR-алгоритм (Qwen): все собственные значения:\")\n",
    "    for i in range(len(eigenvalues_qr_qwen)):\n",
    "        print(f\"{i + 1}-е собственное значение: {eigenvalues_qr_qwen[i]}\")\n",
    "        print(f\"Соответствующий собственный вектор: {eigenvectors_qr_qwen[:, i]}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при выполнении QR - алгоритма от Qwen: {str(e)}\")\n",
    "\n",
    "# Использование сниппетов от Claude\n",
    "print(\"\\nРезультаты от Claude:\")\n",
    "try:\n",
    "    eigenvalue_claude, eigenvector_claude = power_method(A)\n",
    "    print(\"Метод Степени (Claude)\")\n",
    "    print(\"Главное собственное значение:\", eigenvalue_claude)\n",
    "    print(\"Соответствующий собственный вектор:\", eigenvector_claude)\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при выполнении метода Степени от Claude: {str(e)}\")\n",
    "\n",
    "shift = 3.0\n",
    "try:\n",
    "    eigenvalue_shifted_claude, eigenvector_shifted_claude = shifted_power_method(A, shift)\n",
    "    print(\"Сдвинутый Метод Степени (Claude)\")\n",
    "    print(\"Собственное значение при сдвиге:\", eigenvalue_shifted_claude + shift)\n",
    "    print(\"Соответствующий собственный вектор при сдвиге:\", eigenvector_shifted_claude)\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при выполнении сдвинутого метода Степени от Claude: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    A_eigenvalues_claude = qr_algorithm(A)\n",
    "    print(\"QR-алгоритм (Claude):\")\n",
    "    print(\"Спектр собственных значений:\\n\", np.diag(A_eigenvalues_claude))\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при выполнении QR - алгоритма от Claude: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65965f46",
   "metadata": {},
   "source": [
    "### 6.4. Анализ полученных результатов\n",
    "\n",
    "|Модель|Комментарий|\n",
    "|---|---|\n",
    "|Qwen|Мне кажется в Qwen реализация методов более детальная и полноценная.  В Методе Степени и Сдвинутом Методе используются вычисления и ортогонализация, что позволяет получать более точные собственные значения и векторы. QR-алгоритм вычисляет и сортирует векторы, увеличивая функциональность. Однако высокая сложность и множество итераций могут замедлить выполнение и вызвать проблемы с сходимостью для сложных матриц.|\n",
    "|Claude|Тут код реализации методов более прост и понятен, основан на итерационных процессах с векторами и матрицами. Думаю это может привести к менее точной оценке.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4e1c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9de463",
   "metadata": {},
   "source": [
    "## Раздел 7. Оптимизация LLM при помощи метода главных компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1846a",
   "metadata": {},
   "source": [
    "### Справка: Метод главных компонент простыми словами с акцентом на собственные числа и собственные векторы\n",
    "\n",
    "**Определение**\n",
    "\n",
    "Метод главных компонентов (PCA - Principal Component Analysis) это подход к уменьшению размерности, такой что:\n",
    "1. Находит новые оси (основные компоненты), где данные отличаются больше всего.\n",
    "2. Проецирует данные на меньшее количество измерений, сохраняя при этом максимальную дисперсию.\n",
    "\n",
    "**Как это работает с позиции собсвенных чисел и векторов:**\n",
    "1. Берем матрицу данных `X` (например, включения токенов или скрытые слои LLM).\n",
    "2. Вычисляем ковариационную матрицу:  \n",
    "   $$\n",
    "   C = \\frac{1}{n} X^T X\n",
    "   $$\n",
    "3. Находим собственные числа и собственные векторы ковариационной матрицы`C`.\n",
    "   - *Собственные векторы* = направления (главные компоненты)\n",
    "   - *Собственные числа* = величина отклонения (дисперсии), зафиксированная в каждом направлении\n",
    "4. Выберем только *топ-k собственных векторов* (наибольшие собственные числа) → получим сокращённое число измерений.\n",
    "\n",
    "**Значение метода главных компонент для оптимизации размера LLM**\n",
    "\n",
    "1. Сжатия слоев встраивания (embedding kayers) или скрытых представлений\n",
    "- Пример: Вы сокращаете 768-мерные встраивания BERT до 128D, используя 128 лучших собственных векторов → огромная экономия памяти.\n",
    "- Полезно для **дистилляции**, **квантования** или **работе на устройстве**.\n",
    "\n",
    "2. Удалить избыточность в пространствах внимания (attention matrix)/фичах (Feature spaces)\n",
    "- Заголовки внимания часто имеют \"низкоуровневую структуру\" (например, всего несколько доминирующих собственных мод).\n",
    "- PCA может выявлять и \"сокращать\" или объединять заголовки, которые обладают сходными характеристиками.\n",
    "\n",
    "3. Проанализировать репрезентативную способность\n",
    "Построение собственного значения **спектра** скрытых состояний говорит вам:\n",
    "- Насколько выразительная часть модели сосредоточена всего в нескольких направлениях.\n",
    "- Является ли результат работы слоя **низкоуровневым** (сжимаемым).\n",
    "\n",
    "\n",
    "### Визуальное представление\n",
    "- **Плоская кривая собственных значений** → разнообразные, высокоуровневые представления (сложнее сжимать).\n",
    "- **Крутой спад собственных значений** → большая часть информации сосредоточена в нескольких направлениях (легко сжимается с помощью PCA).\n",
    "\n",
    "### Реальное приложение:\n",
    "Google, Meta и HuggingFace использовали PCA и **низкоуровневую аппроксимацию** (например, усеченный SVD, линейные узкие места) для:\n",
    "  - Сжатия моделей для мобильного развертывания.\n",
    "  - Ускорения вывода.\n",
    "  - Понять, на что модель \"обращает внимание\".\n",
    "\n",
    "\n",
    "\n",
    "**PCA использует собственные значения/векторы ковариационной матрицы для определения доминирующих направлений в данных. В LLMs PCA выявляет избыточную структуру и обеспечивает сжатие путем проецирования вложений/выходных данных в подпространство меньшей размерности, что делает модели более быстрыми и компактными без существенной потери точности.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8658d43",
   "metadata": {},
   "source": [
    "7.1. Протокол запросов к выбранному (одному) ассистенту. Вы должны убедить его предоставить вам код оптимизации модели LLM (с которой Вы начинали работать в разделах 3-4), использующий метод главных компонентов с акцентом на использование методов расчёта собственных значений и собсвенных векторов. Также необходимо протестировать точность до и после оптимизации при помощи сокращённого набора данных (например, Tiny BERTScore (50 примеров)). Для оптимизации слой можно использовать любой, какой выберете или какой насоветует AI. Не обязательно сокращать все слои.\n",
    "\n",
    "7.2. Полученный в результате код (обновляете в процессе работы над этим разделом, можно оставить только то, что получится в итоге)\n",
    "\n",
    "7.3. Анализ трудностей и галлюцинаций на этом этапе. Как вы с этим справлялись (выявляли и исправляли).\n",
    "\n",
    "7.4. Анализ полученной оптимизированной модели и применения метода"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2afffc",
   "metadata": {},
   "source": [
    "### 7.1. Протокол запросов к выбранному ассистенту.\n",
    "\n",
    "Укажите, какой выбрали в итоге AI-ассистент. Приведите список промптов, которые вы пробовали.\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "**Ассистент** : Qwen\n",
    "\n",
    "**Промпты**:\n",
    "\n",
    "1. Пожалуйста, предложи мне несколько небольших моделей с весами LLM (Large Language Model), которые можно скачать для дальнейшей работы с ними как с матрицей. Модели должны быть небольшими по размеру для экономии времени скачивания и чтобы матрицы, с которыми они будут работать, не были слишком большими. В ответе укажи название модели, ее размер и ссылку на источник скачивания, если таковая есть.\n",
    "\n",
    "2. Пожалуйста, предоставьте мне Python - сниппеты для реализации следующих методов расчета собственных значений и собственных векторов матриц: Метод Степени (Power Method) для нахождения главного собственного значения и соответствующего собственного вектора, Сдвинутый Метод Степени (Shifted Power Method) для нахождения других собственных значений и векторов, а также QR - алгоритм для нахождения всего спектра собственных значений и векторов. В сниппетах используйте стандартные библиотеки Python, такие как Numpy и Scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20106e",
   "metadata": {},
   "source": [
    "### 7.2. Полученный код (в результате совместной работы и доработок):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Загрузка оригинальной модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Оригинальная модель загружена\n",
      "\n",
      "🔍 Найденные линейные слои:\n",
      "1. lm_head\n",
      "\n",
      "⚙️ Будет оптимизирован слой: lm_head\n",
      "\n",
      "🔍 Генерация текста ДО оптимизации:\n",
      "📄 До оптимизации:\n",
      " The future of AI is not without its own challenges. We need to start creating AI based on the knowledge and experience of the human being.\n",
      "\n",
      "The best way to make AI work in the world is to create a set of intelligent, intelligent and human robots. A set\n",
      "\n",
      "🛠 Начинаем оптимизацию слоя...\n",
      "\n",
      "🔄 Оптимизация слоя 'lm_head'...\n",
      "Оригинальная форма весовой матрицы: (50257, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новая форма весовой матрицы: (50257, 768)\n",
      "\n",
      "🔍 Генерация текста ПОСЛЕ оптимизации:\n",
      "📄 После оптимизации:\n",
      " The future of AI is data user software software digital software real computer software technology user use use user user device digital use system design design software use act act object object display object act present object name object encounter object express object inhabit object enter object alter object address object associate object exhibit object\n",
      "\n",
      "✅ Сравнение результатов завершено.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 1. Функция для PCA через SVD\n",
    "# ————————————————————————————————\n",
    "\n",
    "def pca_svd(matrix: np.ndarray, n_components: int):\n",
    "    matrix_centered = matrix - np.mean(matrix, axis=0)\n",
    "    U, S, Vt = np.linalg.svd(matrix_centered, full_matrices=False)\n",
    "    components = Vt[:n_components]\n",
    "    reduced_matrix = matrix_centered @ components.T @ components\n",
    "    return reduced_matrix + np.mean(matrix, axis=0)\n",
    "\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 2. Оптимизация одного линейного слоя с помощью PCA\n",
    "# ————————————————————————————————\n",
    "\n",
    "def optimize_layer_with_pca(model, layer_name: str, n_components: int):\n",
    "    modules = dict(model.named_modules())\n",
    "\n",
    "    if layer_name not in modules:\n",
    "        raise ValueError(f\"Слой '{layer_name}' не найден в модели\")\n",
    "\n",
    "    layer = modules[layer_name]\n",
    "\n",
    "    if not isinstance(layer, torch.nn.Linear):\n",
    "        raise ValueError(\"Выбранный модуль должен быть torch.nn.Linear\")\n",
    "\n",
    "    # Преобразуем веса в numpy\n",
    "    weight_matrix = layer.weight.data.cpu().numpy()\n",
    "    print(f\"🔄 Оптимизация слоя '{layer_name}'...\")\n",
    "    print(\"Оригинальная форма весовой матрицы:\", weight_matrix.shape)\n",
    "\n",
    "    # Применяем PCA/SVD\n",
    "    reduced_weight = pca_svd(weight_matrix, n_components=n_components)\n",
    "\n",
    "    # Обновляем веса в слое\n",
    "    with torch.no_grad():\n",
    "        layer.weight.data = torch.tensor(reduced_weight, dtype=layer.weight.dtype, device=layer.weight.device)\n",
    "\n",
    "    print(\"Новая форма весовой матрицы:\", reduced_weight.shape)\n",
    "\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 3. Генерация текста\n",
    "# ————————————————————————————————\n",
    "\n",
    "def generate_response(model, tokenizer, input_text=\"Artificial Intelligence is\"):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 4. Автоматический выбор подходящего слоя\n",
    "# ————————————————————————————————\n",
    "\n",
    "def find_linear_layers(model):\n",
    "    linear_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            linear_layers.append(name)\n",
    "    return linear_layers\n",
    "\n",
    "\n",
    "# ————————————————————————————————\n",
    "# 5. Основной запуск\n",
    "# ————————————————————————————————\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MODEL_NAME = \"distilgpt2\"\n",
    "    N_COMPONENTS = 64\n",
    "\n",
    "    print(\"📥 Загрузка оригинальной модели...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    original_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).eval()\n",
    "    print(\"✅ Оригинальная модель загружена\\n\")\n",
    "\n",
    "    # Ищем все подходящие слои\n",
    "    linear_layers = find_linear_layers(original_model)\n",
    "    print(\"🔍 Найденные линейные слои:\")\n",
    "    for i, name in enumerate(linear_layers):\n",
    "        print(f\"{i+1}. {name}\")\n",
    "\n",
    "    # Выбираем первый доступный Linear слой\n",
    "    LAYER_TO_OPTIMIZE = linear_layers[0] if len(linear_layers) > 0 else None\n",
    "\n",
    "    if not LAYER_TO_OPTIMIZE:\n",
    "        raise ValueError(\"Не найдено ни одного линейного слоя для оптимизации\")\n",
    "    else:\n",
    "        print(f\"\\n⚙️ Будет оптимизирован слой: {LAYER_TO_OPTIMIZE}\")\n",
    "\n",
    "    print(\"\\n🔍 Генерация текста ДО оптимизации:\")\n",
    "    prompt = \"The future of AI is\"\n",
    "    response_before = generate_response(original_model, tokenizer, prompt)\n",
    "    print(\"📄 До оптимизации:\\n\", response_before)\n",
    "\n",
    "    print(\"\\n🛠 Начинаем оптимизацию слоя...\\n\")\n",
    "    optimized_model = original_model\n",
    "    optimize_layer_with_pca(optimized_model, LAYER_TO_OPTIMIZE, n_components=N_COMPONENTS)\n",
    "\n",
    "    print(\"\\n🔍 Генерация текста ПОСЛЕ оптимизации:\")\n",
    "    response_after = generate_response(optimized_model, tokenizer, prompt)\n",
    "    print(\"📄 После оптимизации:\\n\", response_after)\n",
    "\n",
    "    print(\"\\n✅ Сравнение результатов завершено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a97514",
   "metadata": {},
   "source": [
    "### 7.3. Анализ трудностей и галлюцинаций на этом этапе. Как вы с этим справлялись (выявляли и исправляли).\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "На данном этапе возникли некоторые ключевые трудности. Также были зафиксированы признаки галлюцинаций, особенно в части выбора и загрузки модели.\n",
    "\n",
    "### Основные трудности:\n",
    "1. **Недоступность указанной модели**\n",
    "    - **Проблема**: Модель `PY007/TinyLlama - 1.1B - python` оказалась либо удалённой, либо стала приватной.\n",
    "    - **Вызов ошибки**: `HTTPError: 401 Unauthorized`, `RepositoryNotFoundError`.\n",
    "    - **Как решали**:\n",
    "        - Проверили доступность модели через Hugging Face Hub.\n",
    "        - Найдли альтернативу среди публично доступных моделей, например, `distilgpt2`.\n",
    "        - Обновили код для новой модели и соответствующий слой. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69f14f",
   "metadata": {},
   "source": [
    "### 7.4. Анализ полученной оптимизированной модели и применения метода\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "Мы использовали метод главных компонентов (PCA) на одном из линейных слоев малой языковой модели (distilgpt2) для сжатия весовой матрицы через понижение ранга. Это принесло нам следующие преимущества:\n",
    "- Сокращение числа параметров в слое.\n",
    "- Сохранение структуры и функциональности модели.\n",
    "- Проверка влияния на качество генерации текста.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45712c46",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734eb5d",
   "metadata": {},
   "source": [
    "Что хочется добавить к сегодняшнему занятию:\n",
    "\n",
    "1. [Код](https://github.com/tongjingqi/MathTrap) со ссылкой на статью про математические ловушки для LLM\n",
    "\n",
    "2. [Заметка](https://habr.com/ru/articles/904754/) о том, какие навыки *кажется следует* подтягивать программистам в современной индустрии\n",
    "\n",
    "3. Работая с различными AI-ассистентами, по крайней мере в Университете, будьте готовы к тому, что Вы не сможете получить максимум баллов за выполненные с их помощью работы, если только в задании не требуется обратное. Я провела опрос среди преподавателей нашего факультета (участие приняли 30 человек). 50% преподавателей высказались о том, что не поставят максимальный балл за работу выполненную с помощью GPT и аналогов, предлагая урезать баллы минимум в половину. Ещё 30% процентов поставят 0 баллов за такую работу и только лишь 20% преподавателей согласны принять работу выполненную при помощи ИИ-агентов и оценивать как выполненную самостоятельно. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a847da",
   "metadata": {},
   "source": [
    "## Итог\n",
    "\n",
    "Расскажите о Вашем сегодняшнем опыте: если это привычный способ изучения новой области, прототипирования, то на сколько удалось погрузиться в тему собственных чисел и оптимизации LLM. Если вообще все Вам показалось новым, включая общение с LLM, то расскажите, как Вы справлись с написанием промптов и кода? Если писали пропты на языке отличном от родного, то на сколько трудно это Вам показалось и какие подходы использовали (например, машинный перевод?)\n",
    "\n",
    "Как Вы сами оцениваете свой прогресс на сегодняшнем занятии?\n",
    "\n",
    "Удалось ли Вам изучить всё то, что перечисленно в самом первом списке в ноутбуке? Что вызвало наибольшее затруднение?\n",
    "\n",
    "*ВАШ КОММЕНТАРИЙ ЗДЕСЬ*\n",
    "\n",
    "Сегодняшний опыт изучения собственных чисел и оптимизации LLM был для меня очень увлекательным и одновременно необычным. В некоторых моментах возникали проблемы, иногда я не понимала сути задачи, но думаю в итоге я неплохо справилась. \n",
    "\n",
    "Было интересно реализовывать разные методы с помощью ассистентов, а так же своими знаниями и сравнивать всё это. Больше всего мне понравилось работать с Qwen, так как он давал полные ответы и его интерфейс был более понетен нежели Claude (он не запал мне в душу).\n",
    "\n",
    "Сначала я думала о написании промптов на анлийском языке, но довольно таки скоро отказалась от этой идеи, так как было трудно передать суть своих мыслей. Поэтому я остановила свой выбор на русском языке, при том что он тоже не мой родной язык, но всё же более понятный чем английский 😁."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
